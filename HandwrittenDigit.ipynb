{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5d2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078162c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4375e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "def pad_to_square(img, pad_value=0):\n",
    "    \"\"\"Pad the image to make it square (for uniform 28x28 resizing).\"\"\"\n",
    "    h, w = img.shape\n",
    "    diff = abs(h - w)\n",
    "    if h > w:\n",
    "        pad_left = diff // 2\n",
    "        pad_right = diff - pad_left\n",
    "        padded = cv2.copyMakeBorder(img, 0, 0, pad_left, pad_right, cv2.BORDER_CONSTANT, value=pad_value)\n",
    "    else:\n",
    "        pad_top = diff // 2\n",
    "        pad_bottom = diff - pad_top\n",
    "        padded = cv2.copyMakeBorder(img, pad_top, pad_bottom, 0, 0, cv2.BORDER_CONSTANT, value=pad_value)\n",
    "    return padded\n",
    "def extract_digits_from_page(image_path, save_dir, label, min_width=10, min_height=10, preview=False):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(f\"\\n📄 Processing: {image_path} | Detected: {len(contours)} blobs\")\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    bounding_boxes.sort(key=lambda b: (b[1], b[0]))  # sort top-to-bottom, then left-to-right\n",
    "    save_path = os.path.join(save_dir, str(label))\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    count = 0\n",
    "    for i, (x, y, w, h) in enumerate(bounding_boxes):\n",
    "        if w >= min_width and h >= min_height:\n",
    "            roi = thresh[y:y+h, x:x+w]\n",
    "            roi_padded = pad_to_square(roi)\n",
    "            digit_resized = cv2.resize(roi_padded, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "            file_path = os.path.join(save_path, f\"{label}_{count}.png\")\n",
    "            cv2.imwrite(file_path, digit_resized)\n",
    "            count += 1\n",
    "            if preview:\n",
    "                cv2.imshow(\"Digit\", digit_resized)\n",
    "                key = cv2.waitKey(150)\n",
    "                if key == 27:  # Esc key to stop preview\n",
    "                    break\n",
    "    if preview:\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    print(f\"✅ Saved {count} digits to {save_path}\")\n",
    "def process_folder(folder_path, save_dir):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Example file naming: digit_4_page1.jpg → label = 4\n",
    "            try:\n",
    "                label = int(file_name.split('_')[1])  # assumes format: digit_4_page1.jpg\n",
    "            except:\n",
    "                print(f\"⚠️ Skipping {file_name} (could not determine label)\")\n",
    "                continue\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            extract_digits_from_page(image_path, save_dir, label, preview=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17abda60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_0_page1.jpg | Detected: 55 blobs\n",
      "✅ Saved 26 digits to custom_digit\\0\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_0_page11.jpg | Detected: 314 blobs\n",
      "✅ Saved 60 digits to custom_digit\\0\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_1_page13.jpg | Detected: 136 blobs\n",
      "✅ Saved 35 digits to custom_digit\\1\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_1_page2.jpg | Detected: 64 blobs\n",
      "✅ Saved 23 digits to custom_digit\\1\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_2_page14.jpg | Detected: 198 blobs\n",
      "✅ Saved 58 digits to custom_digit\\2\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_2_page3.jpg | Detected: 72 blobs\n",
      "✅ Saved 33 digits to custom_digit\\2\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_3_page16.jpg | Detected: 125 blobs\n",
      "✅ Saved 25 digits to custom_digit\\3\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_3_page4.jpg | Detected: 82 blobs\n",
      "✅ Saved 29 digits to custom_digit\\3\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_4_page15.jpg | Detected: 118 blobs\n",
      "✅ Saved 16 digits to custom_digit\\4\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_4_page5.jpg | Detected: 204 blobs\n",
      "✅ Saved 29 digits to custom_digit\\4\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_5_pa.jpg | Detected: 113 blobs\n",
      "✅ Saved 45 digits to custom_digit\\5\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_5_page17.jpg | Detected: 113 blobs\n",
      "✅ Saved 45 digits to custom_digit\\5\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_5_page6.jpg | Detected: 38 blobs\n",
      "✅ Saved 23 digits to custom_digit\\5\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_6_page18.jpg | Detected: 69 blobs\n",
      "✅ Saved 22 digits to custom_digit\\6\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_6_page7.jpg | Detected: 118 blobs\n",
      "✅ Saved 48 digits to custom_digit\\6\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_7_page20.jpg | Detected: 198 blobs\n",
      "✅ Saved 32 digits to custom_digit\\7\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_7_page8.jpg | Detected: 48 blobs\n",
      "✅ Saved 26 digits to custom_digit\\7\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_8_page19.jpg | Detected: 62 blobs\n",
      "✅ Saved 18 digits to custom_digit\\8\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_8_page21.jpg | Detected: 381 blobs\n",
      "✅ Saved 47 digits to custom_digit\\8\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_8_page9.jpg | Detected: 133 blobs\n",
      "✅ Saved 39 digits to custom_digit\\8\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_9_page10.jpg | Detected: 77 blobs\n",
      "✅ Saved 35 digits to custom_digit\\9\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_9_page12.jpg | Detected: 96 blobs\n",
      "✅ Saved 15 digits to custom_digit\\9\n",
      "\n",
      "📄 Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_9_page22.jpg | Detected: 58 blobs\n",
      "✅ Saved 17 digits to custom_digit\\9\n",
      "⚠️ Skipping image1.jpg (could not determine label)\n",
      "⚠️ Skipping WhatsApp Image 2025-08-13 at 01.19.12_98757569.jpg (could not determine label)\n"
     ]
    }
   ],
   "source": [
    "process_folder(r\"C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\",\"custom_digit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fdfa112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "def add_noise(img):\n",
    "    noise = np.random.randint(0, 50, img.shape, dtype='uint8')\n",
    "    return cv2.add(img, noise)\n",
    "def rotate_image(img, angle):\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
    "    return cv2.warpAffine(img, M, (w, h), borderValue=255)\n",
    "def shift_image(img, x_shift, y_shift):\n",
    "    M = np.float32([[1, 0, x_shift], [0, 1, y_shift]])\n",
    "    return cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), borderValue=255)\n",
    "def scale_image(img, fx, fy):\n",
    "    return cv2.resize(img, None, fx=fx, fy=fy, interpolation=cv2.INTER_LINEAR)\n",
    "def invert_image(img):\n",
    "    return 255 - img\n",
    "# Augment images in-place inside 'custom_digits' folder\n",
    "base_dir = r\"C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\custom_digit\"\n",
    "for digit in os.listdir(base_dir):\n",
    "    digit_path = os.path.join(base_dir, digit)\n",
    "    if not os.path.isdir(digit_path):\n",
    "        continue\n",
    "    image_files = [f for f in os.listdir(digit_path) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(digit_path, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # Generate 3 augmentations per image\n",
    "        for i in range(3):\n",
    "            rotated = rotate_image(img, angle=random.choice([-15, -10, 10, 15]))\n",
    "            shifted = shift_image(rotated, random.randint(-3, 3), random.randint(-3, 3))\n",
    "            noisy = add_noise(shifted)\n",
    "            final = invert_image(noisy) if random.random() < 0.5 else noisy\n",
    "            new_filename = f\"{os.path.splitext(img_name)[0]}_aug{i}.png\"\n",
    "            new_path = os.path.join(digit_path, new_filename)\n",
    "            cv2.imwrite(new_path, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bf085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_digits(base_dir):\n",
    "    images, labels = [], []\n",
    "    for label in range(10):  # Assuming folders '0' to '9'\n",
    "        folder = os.path.join(base_dir, str(label))\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "        for fname in os.listdir(folder):\n",
    "            if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                img_path = os.path.join(folder, fname)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                img = img.astype(\"float32\") / 255.0\n",
    "                images.append(np.expand_dims(img, -1))\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "custom_data_dir = r\"C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\custom_digit\"\n",
    "x_custom, y_custom = load_custom_digits(custom_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01185971",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Expand dims to add channel for grayscale\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a75fe3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10), (10905, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "y_custom = to_categorical(y_custom, 10)\n",
    "y_train.shape, y_test.shape, y_custom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76efb7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined training data shape: (70905, 28, 28, 1)\n",
      "Combined training labels shape: (70905, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train_combined = np.concatenate((x_train, x_custom), axis=0)\n",
    "y_train_combined = np.concatenate((y_train, y_custom), axis=0)\n",
    "\n",
    "print(f\"Combined training data shape: {x_train_combined.shape}\")\n",
    "print(f\"Combined training labels shape: {y_train_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b738624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akanksha meshram\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82fb4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define ImageDataGenerator with augmentations similar to your OpenCV ones\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,        # rotate images randomly up to ±15 degrees\n",
    "    width_shift_range=0.1,    # horizontal shift up to 10%\n",
    "    height_shift_range=0.1,   # vertical shift up to 10%\n",
    "    shear_range=0.1,          # shear angle in counter-clockwise direction in degrees\n",
    "    zoom_range=0.1,           # zoom in/out\n",
    "    fill_mode='nearest'       # fill missing pixels with nearest values\n",
    ")\n",
    "\n",
    "# Fit generator to your combined training data (optional for some augmentations)\n",
    "datagen.fit(x_train_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34813275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akanksha meshram\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 93ms/step - accuracy: 0.5945 - loss: 1.1942 - val_accuracy: 0.8938 - val_loss: 0.3275\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/498\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8438 - loss: 0.4610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akanksha meshram\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4610 - val_accuracy: 0.8940 - val_loss: 0.3274\n",
      "Epoch 3/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 93ms/step - accuracy: 0.8350 - loss: 0.5052 - val_accuracy: 0.9172 - val_loss: 0.2648\n",
      "Epoch 4/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.3605 - val_accuracy: 0.9167 - val_loss: 0.2660\n",
      "Epoch 5/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 95ms/step - accuracy: 0.8620 - loss: 0.4258 - val_accuracy: 0.9193 - val_loss: 0.2396\n",
      "Epoch 6/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.3311 - val_accuracy: 0.9185 - val_loss: 0.2421\n",
      "Epoch 7/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 87ms/step - accuracy: 0.8771 - loss: 0.3752 - val_accuracy: 0.9251 - val_loss: 0.2240\n",
      "Epoch 8/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.3080 - val_accuracy: 0.9237 - val_loss: 0.2264\n",
      "Epoch 9/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 95ms/step - accuracy: 0.8825 - loss: 0.3536 - val_accuracy: 0.9248 - val_loss: 0.2203\n",
      "Epoch 10/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.3588 - val_accuracy: 0.9236 - val_loss: 0.2285\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "# Fit the datagen on the combined training data (optional for some augmentations)\n",
    "datagen.fit(x_train_combined)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split combined data into train and validation sets\n",
    "x_train_final, x_val, y_train_final, y_val = train_test_split(\n",
    "    x_train_combined, y_train_combined, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Use the generator only on the training data\n",
    "train_generator = datagen.flow(x_train_final, y_train_final, batch_size=batch_size)\n",
    "\n",
    "# Train with validation data separately (pass x_val, y_val as validation_data)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    steps_per_epoch=len(x_train_final) // batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1545a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to my_digit_model.h5\n"
     ]
    }
   ],
   "source": [
    "# After model.fit(...)\n",
    "model.save('my_digit_model.h5')\n",
    "print(\"Model saved to my_digit_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac2029cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m204,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,036</span> (879.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225,036\u001b[0m (879.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,034</span> (879.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,034\u001b[0m (879.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('my_digit_model.h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d3bd259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST test accuracy: 0.9878\n",
      "Custom dataset accuracy: 0.5908\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"MNIST test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# 10. Evaluate on custom dataset\n",
    "custom_loss, custom_accuracy = model.evaluate(x_custom, y_custom, verbose=0)\n",
    "print(f\"Custom dataset accuracy: {custom_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "021eb799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMQRJREFUeJzt3XtwVGWC/vGnCekEA8kqGUPQ3HQkKDIQmkVCTUDIGBdGXBx3dB0L47I7Y2qt4pLKaABnufx0KS1K3Sm5FFR0R1xL1AbHFXaL7BQBSuLsyna0MIDscknERCYIHVBJCL6/P9g0nHSTpDudpN/w/VSdqrwn56TfnHqAh9Pn9HEZY4wAAAAsMKi/JwAAANBdFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYI2wi8vu3bs1e/ZsjRw5Ui6XS++9916X++zatUsej0eJiYm65ZZbtH79+kjmCvQI2YWtyC5wWdjF5ZtvvtG4ceP0yiuvdGv7o0ePatasWSooKJDP59OSJUs0f/58eb3esCcL9ATZha3ILnCZqycPWXS5XNq6davmzJlz1W2efvppvf/++zpw4EBgXUlJiT755BNVV1dH+tJAj5Bd2Irs4lo3uLdfoLq6WkVFRY519957ryoqKnThwgXFx8cH7dPS0qKWlpbA+Pvvv9fXX3+t4cOHy+Vy9faUMUAZY3T27FmNHDmyW9uTXcQKsgtbXZndQYOic1ltrxeXxsZGpaWlOdalpaWpra1NTU1NSk9PD9pn1apVWrFiRW9PDdeo+vr6bm1HdhFryC5sVV9fr5tvvjkqP6vXi4ukoLbe/u7U1Vr84sWLVVpaGhj7/X5lZmaqvr5eycnJvTdRDGjNzc3KyMjQsGHDur0P2UUsILuwVSTZ7UqvF5cRI0aosbHRse7kyZMaPHiwhg8fHnKfhIQEJSQkBK1PTk7mDxB6rLunvckuYg3Zha2i+XZjr3+OS35+viorKx3rduzYoYkTJ4Z8nxWIFWQXtiK7GMjCLi7nzp1TTU2NampqJF267a6mpkZ1dXWSLp1ufOyxxwLbl5SU6Pjx4yotLdWBAwf06quvqqKiQmVlZdH5DYBuOnfunCTp008/lUR2YQ+yC1zBhGnnzp1GUtBSXFxsjDGmuLjYTJs2zbFPVVWVycvLM26322RnZ5t169aF9Zp+v99IMn6/P9zpAgEffPAB2YWVyC5s1Rs56tHnuPSV5uZmpaSkyO/3814rItYfOSK7iAayC1v1Ro54VhEAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYA2KCwAAsAbFBQAAWIPiAgAArEFxAQAA1qC4AAAAa1BcAACANSguAADAGhQXAABgDYoLAACwBsUFAABYg+ICAACsQXEBAADWoLgAAABrUFwAAIA1KC4AAMAaFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYA2KCwAAsAbFBQAAWIPiAgAArEFxAQAA1qC4AAAAa1BcAACANSguAADAGhQXAABgDYoLAACwBsUFAABYg+ICAACsEVFxWbt2rXJycpSYmCiPx6M9e/Zcdduqqiq5XK6g5eDBgxFPGuiJsWPHkl1YiewCERSXzZs3a+HChVq6dKl8Pp8KCgo0c+ZM1dXVdbrfoUOH1NDQEFhuu+22iCcNRMLr9UqSysrKyC6sQnaBK5gwTZo0yZSUlDjWjR492pSXl4fcfufOnUaSOX36dLgvFeD3+40k4/f7I/4ZgMfjCcoR2YUNyC5s1Rs5CuuMS2trq/bt26eioiLH+qKiIu3du7fTffPy8pSenq7CwkLt3Lmz021bWlrU3NzsWICeaG1tVU1NTdB6sotYR3YBp7CKS1NTky5evKi0tDTH+rS0NDU2NobcJz09XRs2bJDX69WWLVuUm5urwsJC7d69+6qvs2rVKqWkpASWjIyMcKYJBGnPbkdkF7GO7AJOgyPZyeVyOcbGmKB17XJzc5WbmxsY5+fnq76+XqtXr9bUqVND7rN48WKVlpYGxs3NzfwhQq8gu7AV2cW1KqwzLqmpqYqLiwtq+SdPngw6C9OZyZMn6/Dhw1f9fkJCgpKTkx0L0BPt2e2I7CLWkV3AKazi4na75fF4VFlZ6VhfWVmpKVOmdPvn+Hw+paenh/PSQI+43W6NHz8+aD3ZRawju4BT2G8VlZaWau7cuZo4caLy8/O1YcMG1dXVqaSkRNKl040nTpzQ66+/Lkl6+eWXlZ2drTFjxqi1tVVvvPGGvF5v4PY+oK88+eSTmjdvnjZt2qQZM2aQXViD7AKXhV1cHn74YZ06dUorV65UQ0OD7rzzTm3fvl1ZWVmSpIaGBsdnC7S2tqqsrEwnTpzQkCFDNGbMGG3btk2zZs2K3m8BdMODDz6oefPm6YUXXlBpaSnZhTXILnCZyxhj+nsSXWlublZKSor8fj/vuyJi/ZEjsotoILuwVW/kiGcVAQAAa1BcAACANSguAADAGhQXAABgDYoLAACwBsUFAABYg+ICAACsQXEBAADWoLgAAABrUFwAAIA1KC4AAMAaFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYA2KCwAAsAbFBQAAWIPiAgAArEFxAQAA1qC4AAAAa1BcAACANSguAADAGhQXAABgDYoLAACwBsUFAABYg+ICAACsQXEBAADWoLgAAABrUFwAAIA1KC4AAMAaFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYI2IisvatWuVk5OjxMREeTwe7dmzp9Ptd+3aJY/Ho8TERN1yyy1av359RJMFomHs2LFkF1Yiu0AExWXz5s1auHChli5dKp/Pp4KCAs2cOVN1dXUhtz969KhmzZqlgoIC+Xw+LVmyRPPnz5fX6+3x5IFwtGeurKyM7MIqZBe4zGWMMeHscNddd2nChAlat25dYN3tt9+uOXPmaNWqVUHbP/3003r//fd14MCBwLqSkhJ98sknqq6uDvkaLS0tamlpCYz9fr8yMzNVX1+v5OTkcKYLBEybNk01NTU6c+aMUlJSJJFd2IHswlbNzc3KyMhwZLfHTBhaWlpMXFyc2bJli2P9/PnzzdSpU0PuU1BQYObPn+9Yt2XLFjN48GDT2toacp9ly5YZSSwsvbL87//+L9llsXIhuyy2Lldmt6cGKwxNTU26ePGi0tLSHOvT0tLU2NgYcp/GxsaQ27e1tampqUnp6elB+yxevFilpaWB8ZkzZ5SVlaW6urroNbYBpr3V8r+j0BoaGjR69GhJ0g033BBYT3b7H9ntHNmNXWS3a+1n7q7Mbk+FVVzauVwux9gYE7Suq+1DrW+XkJCghISEoPUpKSmEowvJyckcoxDOnTsX+HrQoMuXdpHd2EF2QyO7sY/sdu3K7Pb4Z4WzcWpqquLi4oJa/smTJ4PafbsRI0aE3H7w4MEaPnx4mNMFItOe3Y7ILmId2QWcwioubrdbHo9HlZWVjvWVlZWaMmVKyH3y8/ODtt+xY4cmTpyo+Pj4MKcLRMbtdmv8+PFB68kuYh3ZBToI96KYt956y8THx5uKigpTW1trFi5caJKSksyxY8eMMcaUl5ebuXPnBrY/cuSIue6668yiRYtMbW2tqaioMPHx8ebdd9/t9mueP3/eLFu2zJw/fz7c6V4zOEZd27Rpkxk0aJBZv3492Y0hHKOukd3YxDHqWm8co7CLizHGrFmzxmRlZRm3220mTJhgdu3aFfhecXGxmTZtmmP7qqoqk5eXZ9xut8nOzjbr1q3r0aSBSJFd2IrsApeE/TkuAAAA/YVnFQEAAGtQXAAAgDUoLgAAwBoUFwAAYI2YKS5r165VTk4Oj2zvRDjHqKqqSi6XK2g5ePBgH8647+zevVuzZ8/WyJEj5XK59N5773W5T7QyRHa7RnavjuzGNrJ7df2W3f6+rcmYy58Ns3HjRlNbW2sWLFhgkpKSzPHjx0Nu3/4ZBQsWLDC1tbVm48aNYX9GgW3CPUY7d+40ksyhQ4dMQ0NDYGlra+vjmfeN7du3m6VLlxqv12skma1bt3a6fbQyRHa7RnY7R3ZjF9ntXH9lNyaKy6RJk0xJSYlj3ejRo015eXnI7Z966ikzevRox7onnnjCTJ48udfm2N/CPUbtf4BOnz7dB7OLLd35AxStDJHdrpHd7iO7sYXsdl9fZrff3ypqbW3Vvn37VFRU5FhfVFSkvXv3htynuro6aPt7771XH3/8sS5cuNBrc+0vkRyjdnl5eUpPT1dhYaF27tzZm9O0SjQyRHa7Rnajj+z2DbIbfdHKUL8Xl6amJl28eDHkI9gjfWT7QBPJMUpPT9eGDRvk9Xq1ZcsW5ebmqrCwULt37+6LKce8aGSI7HaN7EYf2e0bZDf6opWhwdGeWKRCPYI9mo9sHwjCOUa5ubnKzc0NjPPz81VfX6/Vq1dr6tSpvTpPW0QrQ2S3a2Q3ushu3yG70RWNDIV9xiXaVxG3P7I91CPYeWT7JZEco1AmT56sw4cPR3t61rgyu4cPH9aHH37o+H6oDJHdniG70UF2+x7Zjb5oZSjs4vLNN99o3LhxeuWVV7q1/dGjRzVr1iwVFBTI5/NpyZIlmj9/vrxer6RLj2z3eDxBj2Dnke2XRXKMQvH5fEpPT4/29KzRMbuffPKJ4/sdM0R2e47sRgfZ7XtkN/qilqGwLuXtQFG6irj9lrOKioo+e2S7bcI9Ri+99JLZunWr+fzzz83+/ftNeXm5kWS8Xm9//Qq96uzZs8bn8xmfz2ckmRdffNH4fL7AbYsdj48k43a7O80Q2Y0Osts5shu7yG7nws1utDLU69e4XO0q4oqKCl24cEHx8fF6+OGHderUKa1cuVINDQ2644479M477+j6669Xc3Ozjh49qiNHjsjv98vlcmn48OF65513tHjxYr3yyitKT0/X888/r3vuuUfNzc29/Sv1i5kzZ2rVqlVavny5Ghsbg47R8ePHVVdXF/j9m5ubVVpaqi+//FJDhgzR6NGj9c477+gnP/nJgDxGe/bs0X333RcYl5aWSpIeeeQRrV+/XsePH9fx48f1xRdfaOTIkZKk3/zmN9qyZYvWrFmjkSNH6re//a0efPDBwM8gu9FBdjtHdmMX2e1cuNnNycnR9u3btWjRoqtmt1t60rbUjTMut912m3nuuecc6z788EMjyXz55Zch91m2bJmRxMLSK0t9fb2RyC6LfQvZZbF1qa+v7zSz4eiTu4rCvYp48eLFgeYmSX6/X5mZmaqvr1dycnLvTRQDWnNzszIyMjRs2LBu70N2EQvILmwVSXa70uvFJZKriBMSEpSQkBC0Pjk5mT9A6LHu3nZHdhFryC5sFc1b5nv9A+iutSvRMXCQXdiK7GIgC7u4nDt3TjU1NaqpqZF06ba7mpoa1dXVSbp0uvGxxx4LbF9SUqLjx4+rtLRUBw4c0KuvvqqKigqVlZVF5zcAuuncuXOSpE8//VQS2YU9yC5whXAviml/iFTHpbi42BhjTHFxsZk2bZpjn6qqKpOXl2fcbrfJzs4269atC+s1/X6/kWT8fn+40wUCPvjgA7ILK5Fd2Ko3cuQy5v+u2Iphzc3NSklJkd/v571WRKw/ckR2EQ1kF7bqjRz1+0MWAQAAuoviAgAArEFxAQAA1qC4AAAAa1BcAACANSguAADAGhQXAABgDYoLAACwBsUFAABYg+ICAACsQXEBAADWoLgAAABrUFwAAIA1KC4AAMAaFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYA2KCwAAsAbFBQAAWIPiAgAArEFxAQAA1qC4AAAAa1BcAACANSguAADAGhQXAABgDYoLAACwBsUFAABYg+ICAACsQXEBAADWoLgAAABrUFwAAIA1KC4AAMAaFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtEVFzWrl2rnJwcJSYmyuPxaM+ePVfdtqqqSi6XK2g5ePBgxJMGemLs2LFkF1Yiu0AExWXz5s1auHChli5dKp/Pp4KCAs2cOVN1dXWd7nfo0CE1NDQElttuuy3iSQOR8Hq9kqSysjKyC6uQXeAylzHGhLPDXXfdpQkTJmjdunWBdbfffrvmzJmjVatWBW1fVVWl6dOn6/Tp0/qzP/uzbr1GS0uLWlpaAuPm5mZlZGTI7/crOTk5nOkCARMnTtS+ffscOSK7sAHZha2am5uVkpIS1RyFdcaltbVV+/btU1FRkWN9UVGR9u7d2+m+eXl5Sk9PV2FhoXbu3NnptqtWrVJKSkpgycjICGeaQJDW1lbV1NQErSe7iHVkF3AKq7g0NTXp4sWLSktLc6xPS0tTY2NjyH3S09O1YcMGeb1ebdmyRbm5uSosLNTu3buv+jqLFy+W3+8PLPX19eFMEwjSnt2OyC5iHdkFnAZHspPL5XKMjTFB69rl5uYqNzc3MM7Pz1d9fb1Wr16tqVOnhtwnISFBCQkJkUwNCAvZha3ILq5VYZ1xSU1NVVxcXFDLP3nyZNBZmM5MnjxZhw8fDuelgR5pz25HZBexjuwCTmEVF7fbLY/Ho8rKSsf6yspKTZkypds/x+fzKT09PZyXBnrE7XZr/PjxQevJLmId2QWcwn6rqLS0VHPnztXEiROVn5+vDRs2qK6uTiUlJZIuvU964sQJvf7665Kkl19+WdnZ2RozZoxaW1v1xhtvyOv1Bm7vA/rKk08+qXnz5mnTpk2aMWMG2YU1yC5wWdjF5eGHH9apU6e0cuVKNTQ06M4779T27duVlZUlSWpoaHB8tkBra6vKysp04sQJDRkyRGPGjNG2bds0a9as6P0WQDc8+OCDmjdvnl544QWVlpaSXViD7AKXhf05Lv2hN+4Dx7WnP3JEdhENZBe26vfPcQEAAOhPFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYA2KCwAAsAbFBQAAWIPiAgAArEFxAQAA1qC4AAAAa1BcAACANSguAADAGhQXAABgDYoLAACwBsUFAABYg+ICAACsQXEBAADWoLgAAABrUFwAAIA1KC4AAMAaFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYA2KCwAAsAbFBQAAWIPiAgAArEFxAQAA1qC4AAAAa1BcAACANSguAADAGhQXAABgDYoLAACwRkTFZe3atcrJyVFiYqI8Ho/27NnT6fa7du2Sx+NRYmKibrnlFq1fvz6iyQLRMHbsWLILK5FdIILisnnzZi1cuFBLly6Vz+dTQUGBZs6cqbq6upDbHz16VLNmzVJBQYF8Pp+WLFmi+fPny+v19njyQDjaM1dWVkZ2YRWyC1zBhGnSpEmmpKTEsW706NGmvLw85PZPPfWUGT16tGPdE088YSZPntzt1/T7/UaS8fv94U4XCPB4PEE5IruwAdmFrXojR4PDKTmtra3at2+fysvLHeuLioq0d+/ekPtUV1erqKjIse7ee+9VRUWFLly4oPj4+KB9Wlpa1NLSEhj7/X5JUnNzczjTBQJaW1tVU1MjSTLGBNaTXcQ6sgubtefnyuz2VFjFpampSRcvXlRaWppjfVpamhobG0Pu09jYGHL7trY2NTU1KT09PWifVatWacWKFUHrMzIywpkuENKpU6eUkpIiiezCLmQXtroyuz0VVnFp53K5HGNjTNC6rrYPtb7d4sWLVVpaGhifOXNGWVlZqquri9ovPtA0NzcrIyND9fX1Sk5O7u/pxJyGhgaNHj1aknTDDTcE1pPd/kd2O0d2YxfZ7Zrf71dmZqYjuz0VVnFJTU1VXFxcUMs/efJkULtvN2LEiJDbDx48WMOHDw+5T0JCghISEoLWp6SkEI4uJCcnc4xCSExMVFxcnC5evKhBgy5fk052YwfZDY3sxr5Q2T127JhycnL02muv6fHHH+90/8cff1y/+93vgtbn5ubq4MGD0Zxqv7kyuz3+WeFs7Ha75fF4VFlZ6VhfWVmpKVOmhNwnPz8/aPsdO3Zo4sSJId9nBXqD2+3W+PHjg9aTXcQ6snttGDJkiKqrqx3L5s2b+3tasSncq3nfeustEx8fbyoqKkxtba1ZuHChSUpKMseOHTPGGFNeXm7mzp0b2P7IkSPmuuuuM4sWLTK1tbWmoqLCxMfHm3fffbfbr8nV7V3jGHXt1VdfNZLMK6+8QnZjCMeoa2S3b3377bfd2q6zY3T06FEjybz22mtd/pzi4mKTlJQU7jSt0Bs5Cru4GGPMmjVrTFZWlnG73WbChAlm165dge8VFxebadOmObavqqoyeXl5xu12m+zsbLNu3bqwXu/8+fNm2bJl5vz585FM95rAMera+fPnzaxZs0xmZibZjSEco66R3fAtW7bMSDL//d//bR544AEzbNgwk5ycbB599FFz8uTJwHZZWVnmpz/9qfF6vWb8+PEmISHBPP3008YYYxoaGsyvfvUrc9NNN5n4+HiTnZ1tli9fbi5cuGCMuXyMjhw5Yn7+85+boUOHmuTkZPPQQw+Z6upqiovpnRy5jIniPUoAAMSA5cuXa8WKFcrKytJDDz2kn/zkJ/rss8/0m9/8RqNGjdIf//hHxcfHKzs7W62trRoyZIieeeYZ5eTkKCkpSRkZGZo0aZIGDRqkJUuW6NZbb1V1dbWeffZZPfLII3rttdckSd999508Ho++/PJLPfvssxo1apS2bdum9957T3V1dY5rXNqveykuLtY///M/B+b6+OOPa9OmTfrBD36gP/3pT0pPT9ecOXO0cuXKqF7UOlBEdFcRAAA2+NnPfqYXXnhB0qXPvklLS9Ojjz6qt99+W48++qikSxcu19bWatSoUYH9SkpKdPr0aX322WfKzMyUJBUWFmrIkCEqKyvTr3/9a91xxx363e9+pwMHDuj3v/+97r///sDrfPfdd9q4caNjLi6XS3FxcYqLi3OsHzdunMaNG6c777xT0qXHNbz00kv6wx/+oP/6r//S0KFDe+fgWIqHLAIABqz2ctLuoYce0uDBg7Vz587Auh/96EeO0iJJH3zwgaZPn66RI0eqra0tsMycOVPSpXIhSTt37tSwYcMCpaXdL37xi6C5ZGVlqa2tTRUVFY71ixYt0qJFi3TPPffonnvu0bPPPqvXX39dBw8eDCo/4IwLAGAAGzFihGPcfkv4qVOnAutCfSDfV199pX/913+96l1YTU1Nki59sFqo29I7vm64HnjgASUlJemjjz7q0c8ZiCguAIABq7GxUTfddFNg3NbWplOnTjk+zybUh/KlpqbqRz/6kZ577rmQP3fkyJGSpOHDh+s///M/Q75uTxljovr5JwNFzByRtWvXKicnh0e2dyKcY1RVVSWXyxW0DJQPM+po9+7dmj17tkaOHCmXy6X33nuvy32ilSGy2zWye3Vkt3f9y7/8i2P89ttvq62tTXfffXen+913333av3+/qqqq9POf/1w//vGP9cQTT+i7777TxIkTA8Vl+vTpOnv2rN5//31HdqdPny5J+pu/+ZuIsvvuu+/q22+/1eTJk8Pet6/0W3ajdn9SD7R/NszGjRtNbW2tWbBggUlKSjLHjx8PuX37ZxQsWLDA1NbWmo0bN4b9GQW2CfcY7dy500gyhw4dMg0NDYGlra2tj2feN7Zv326WLl1qvF6vkWS2bt3a6fbRyhDZ7RrZ7RzZ7R3tt0NnZWWZX//612bHjh3mpZdeMkOHDjXjxo0zLS0txpjLt0N39OWXX5rU1FQjyTz66KPm1VdfNffff79xu91mxowZpr6+3hhjzDfffGNGjRplUlJSzPz5840k89hjj5mbbrrJSDIvv/xyILvHjh0zcXFxZt68eYHXOXbsmJkyZYr57W9/a7Zv327+7d/+zZSXl5vExEQzZswYc+7cuT44WpHpr+zGRHGZNGmSKSkpcazr7Ue22ybcY9T+l//p06f7YHaxpTt/gKKVIbLbNbLbfWQ3etqLy759+8zs2bPN0KFDzbBhw8wjjzxivvrqq8B2VysuxhiTl5dn7rzzTpOTk2Pi4+PNDTfcYBITE82UKVMcheKLL74wDz74oBkyZIiRZO6//36zd+/eoM9xaf9QuuLi4sC6r7/+2jzwwAMmOzvbDBkyxLjdbnPbbbeZp556ypw5cybqx6W39GV2+/2totbWVu3bty/oEeyRPLL9448/1oULF3ptrv0lkmPULi8vT+np6SosLHRcRX+ti0aGyG7XyG70kd3wZGZm6v3339fZs2fV3NysN998UzfeeGPg+8eOHdMHH3wQtF9ra6s+/fRTrVy5UkeOHFFra6tOnTqlX/3qVxo8eLCSkpIC295000169913tX37dknSp59+qp/97GeaMWOGsrKyAttlZ2fLGOP4DJfrr79eW7Zs0dGjR/Xtt9+qpaVFn3/+uZ5//vkB93DLaGWo34tLU1OTLl68GPIR7JE+sn2gieQYpaena8OGDfJ6vdqyZYtyc3NVWFio3bt398WUY140MkR2u0Z2o4/s9g2yG33RylDM3FUU6hHs0Xxk+0AQzjHKzc1Vbm5uYJyfn6/6+nqtXr1aU6dO7dV52iJaGSK7XSO70UV2+w7Zja5oZKjfz7ikpqYqLi4u5CPYo/nIdptFcoxCmTx5sg4fPhzt6VkpGhkiu10ju9FHdrtn+fLlMsYoNTU1ov3JbvRFK0NhF5do3/7kdrvl8XiCHsHOI9svi+QYheLz+UJ+0NK14srs7tmzR1u2bHF8P1SGyG7PkN3oi0aGyG7XyG70RS1DYV3Ka3rn9qf22/IqKir67JHttgn3GL300ktm69at5vPPPzf79+835eXlRpLxer399Sv0qrNnzxqfz2d8Pp+RZF588UXj8/kCt3aWl5ebGTNmOLLrdrs7zRDZjQ6y27nuZLc3MkR2u0Z2O9df2e3R7dDdKS7dvf1pzZo1Jisrq88e2W6jcI7R888/b2699VaTmJhorr/+evPjH//YbNu2rR9m3Tfab6HtuLTfdtjx+Egy/+///b9OM0R2o4fsXl242TUmehkiu10ju1fXX9l1GfN/V8ZEwOVyaevWrZozZ85Vt5k6dary8vL0T//0T4F1W7du1UMPPaRvv/025OmhlpYWtbS0BMbff/+9vv76aw0fPnxAXwSG3mWM0dmzZzVy5EjFxcWRXVjjyuzyEfC41vX6XUVd3f4U6r2/VatWacWKFb09NVyj6uvru7Ud2UWsqa+v180339zf04gIxd0+PTiv0av65HbocG9/Wrx4sUpLSwNjv9+vzMxM1dfXKzk5ufcmigGtublZGRkZGjZsWLf3IbuIBZFkFxioer24RHL7U0JCghISEoLWJycn85c/eqy7//Mju4g1nLUA+uBzXK61W+gwcJBdAIg9YReXc+fOqaamRjU1NZKko0ePqqamRnV1dZIunSp/7LHHAtuXlJTo+PHjKi0t1YEDB/Tqq6+qoqJCZWVl0fkNgG46d+6cpEvPEZHILgBYyYbbn/x+v5Fk/H5/uNMFAj744AOyCysNhByF+rPHEttLrOrR7dB9pbm5WSkpKfL7/VwngIj1R47ILqJhIOSI63PsE6v1gA8EAAAA1qC4AAAAa1BcAACANSguAADAGhQXAABgDYoLAACwBsUFAABYg+ICAACs0SdPhwYAANL111/vGGdmZoa1//Hjxx3jRYsWOcb79+8PfP355587vvfJJ5+E9VqxijMuAADAGhQXAABgDd4qAgAgSn760586xvfff79jfPfddzvGP/zhD8P6+R3f/snKynKMExISrrpvXFxcWK8VqzjjAgAArEFxAQAA1qC4AAAAa3CNCwAAnbj11lsd4yeffDLw9S9/+UvH94YMGeIYu1yuqM5l1KhRUf15NuKMCwAAsAbFBQAAWIPiAgAArME1LgAAdOLmm292jBcsWNBnr33w4EHH+LPPPuuz145VnHEBAADWoLgAAABrUFwAAIA1uMYFADCgpaamOsYdr1H58MMPHeN///d/d4xbWlocY7/fH/j6m2++cXwvKSnJMd6xY4djvH//fsf4j3/8o2Ps8/kc4++++84x7vh61yLOuAAAAGtQXAAAgDUoLgAAwBpc4wIAGFC6us5k3LhxjvEDDzzQ6c/76KOPHOMJEyYEvj527Jjje5mZmY7xF1984Rh///33nb4WusYZFwAAYA2KCwAAsAbFBQAAWINrXAAAVnO73Y7xm2++6Rh3vKblH//xHx3j//iP/wjr9Tpe13Klurq6sH4WwscZFwAAYA2KCwAAsAbFBQAAWINrXAAAVhk6dKhjvHjxYsf4vvvuc4ybmpoc49WrVzvG3377bRRnh97GGRcAAGANigsAALAGxQUAAFiDa1wAAFaZM2eOY1xeXu4Yd/wslYKCAsfY7/f3yrzQNzjjAgAArEFxAQAA1qC4AAAAa0RUXNauXaucnBwlJibK4/Foz549V922qqpKLpcraDl48GDEkwZ6YuzYsWQXsNiUKVMcS0c+n8+xfPHFF44Fdgu7uGzevFkLFy7U0qVL5fP5VFBQoJkzZ3b5YKlDhw6poaEhsNx2220RTxqIhNfrlSSVlZWRXQCwVNjF5cUXX9Tf/u3f6u/+7u90++236+WXX1ZGRobWrVvX6X433nijRowYEVji4uIinjQQiTVr1kiSiouLyS4AWCqs26FbW1u1b9++oFvPioqKtHfv3k73zcvL0/nz53XHHXfomWee0fTp06+6bUtLi1paWgLj5ubmcKYJBGltbVVNTU3QerIL2Oev/uqvOv3+X/zFXzjGy5Ytc4x///vfO8ah/m5A7ArrjEtTU5MuXryotLQ0x/q0tDQ1NjaG3Cc9PV0bNmyQ1+vVli1blJubq8LCQu3evfuqr7Nq1SqlpKQEloyMjHCmCQRpz25HZBcA7BLRB9C5XC7H2BgTtK5dbm6ucnNzA+P8/HzV19dr9erVmjp1ash9Fi9erNLS0sC4ubmZfwDQK8guANglrDMuqampiouLC/of6smTJ4POwnRm8uTJOnz48FW/n5CQoOTkZMcC9ER7djsiuwBgl7DOuLjdbnk8HlVWVuqBBx4IrK+srNRf/uVfdvvn+Hw+paenh/PSQI+43W6NHz9e+/btc6wnu4B9fvCDHzjG33//vWOckJDgGP/DP/yDY/zMM884xuvXr3eMP/roI8c4MzPTMf6f//mfwNefffZZp3MdM2aMY1xdXe0Yc3t2+MJ+q6i0tFRz587VxIkTlZ+frw0bNqiurk4lJSWSLp0qP3HihF5//XVJ0ssvv6zs7GyNGTNGra2teuONN+T1egO3pgJ95cknn9S8efO0adMmzZgxg+wCgIXCLi4PP/ywTp06pZUrV6qhoUF33nmntm/frqysLElSQ0OD43MxWltbVVZWphMnTmjIkCEaM2aMtm3bplmzZkXvtwC64cEHH9S8efP0wgsvqLS0lOwCgIVcxhjT35PoSnNzs1JSUuT3+7lmABHrjxyRXUTDQMjR1S6Cj0THf7Y6vlXUlY7b81ZRaLFaDyK6qwgAgP6yevVqx/jKO/m6Y9Ag530pf//3f9/pOJr+9Kc/OcZVVVWO8V//9V/32msPFDxkEQAAWIPiAgAArEFxAQAA1uDiXFwzuDgXthoIOYrmxbkdP0wyLy/PMX7zzTcd48GDnZdzdvw0647XvPSljv8EL1++3DF+9tln+3A2TrFaDzjjAgAArEFxAQAA1qC4AAAAa/A5LgAAq1y8eNEx/vjjjx3jUaNGdbp/YWGhYxwfH+8Yd7zO5M///M/DnGH3dbz2x+Px9NprDRSccQEAANaguAAAAGtQXAAAgDW4xgUAcE35wx/+0On3x48f7xh3vMalra0t8PVrr73m+N7GjRsd44ULFzrGv/jFL7o5S1wNZ1wAAIA1KC4AAMAaFBcAAGANrnEBAOAKO3bscIyfe+45x/jKZx/98pe/dHzvhz/8oWN89913h/XaX3zxRVjbX4s44wIAAKxBcQEAANaguAAAAGtwjQsAAFc4cOCAY/z22287xg899NBV950+fXqnP7vjc5a2bdvmGJeXl3dnitc0zrgAAABrUFwAAIA1KC4AAMAaXOMCAMAVvvvuO8e44/OGhg4dGvh64sSJju/deOONjvGxY8cc402bNjnGy5cvj2yS1zDOuAAAAGtQXAAAgDUoLgAAwBpc4wIAQCe++uorx3j27NmBr+fOnev43uTJkx3jFStWOMYnT56M8uyuPZxxAQAA1qC4AAAAa/BWEQAAEep4e3PHMaKPMy4AAMAaFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYA2KCwAAsAbFBQAAWCOi4rJ27Vrl5OQoMTFRHo9He/bs6XT7Xbt2yePxKDExUbfccovWr18f0WSBaBg7dizZBQBLhV1cNm/erIULF2rp0qXy+XwqKCjQzJkzVVdXF3L7o0ePatasWSooKJDP59OSJUs0f/58eb3eHk8eCEd75srKysguAFjKZYwx4exw1113acKECVq3bl1g3e233645c+Zo1apVQds//fTTev/993XgwIHAupKSEn3yySeqrq4O+RotLS1qaWkJjP1+vzIzM1VfX6/k5ORwpgsETJs2TTU1NTpz5oxSUlIkkV3Yobm5WRkZGY7s2sblcvX3FBCmMOtBnxkczsatra3at2+fysvLHeuLioq0d+/ekPtUV1erqKjIse7ee+9VRUWFLly4oPj4+KB9Vq1apRUrVgStz8jICGe6QEinTp0K/OVPdmGTK7Nrm1j9RxD2Cau4NDU16eLFi0pLS3OsT0tLU2NjY8h9GhsbQ27f1tampqYmpaenB+2zePFilZaWBsZnzpxRVlaW6urqrP1D29va/0fG/+xDa2ho0OjRoyVJN9xwQ2A92e1/ZLdr7WfurswucK0Kq7i063jKzxjT6WnAUNuHWt8uISFBCQkJQetTUlL4i60LycnJHKMQzp07F/h60KDLl3aR3dhBdrt2ZXaBa1VYfwpSU1MVFxcX9D/UkydPBv3PtN2IESNCbj948GANHz48zOkCkWnPbkdkFwDsElZxcbvd8ng8qqysdKyvrKzUlClTQu6Tn58ftP2OHTs0ceLEkNcIAL3B7XZr/PjxQevJLgBYxoTprbfeMvHx8aaiosLU1taahQsXmqSkJHPs2DFjjDHl5eVm7ty5ge2PHDlirrvuOrNo0SJTW1trKioqTHx8vHn33Xe7/Zrnz583y5YtM+fPnw93utcMjlHXNm3aZAYNGmTWr19PdmMIx6hrHCPgsrCLizHGrFmzxmRlZRm3220mTJhgdu3aFfhecXGxmTZtmmP7qqoqk5eXZ9xut8nOzjbr1q3r0aSBSJFdALBb2J/jAgAA0F+4RB0AAFiD4gIAAKxBcQEAANaguAAAAGvETHFZu3atcnJylJiYKI/Hoz179nS6/a5du+TxeJSYmKhbbrlF69ev76OZ9p9wjlFVVZVcLlfQcvDgwT6ccd/ZvXu3Zs+erZEjR8rlcum9997rcp9oZYjsdo3sXl1/ZhewUn/f1mTM5c+G2bhxo6mtrTULFiwwSUlJ5vjx4yG3b/98jQULFpja2lqzcePGsD9fwzbhHqOdO3caSebQoUOmoaEhsLS1tfXxzPvG9u3bzdKlS43X6zWSzNatWzvdPloZIrtdI7ud66/sAraKieIyadIkU1JS4lg3evRoU15eHnL7p556yowePdqx7oknnjCTJ0/utTn2t3CPUftf/qdPn+6D2cWW7vzlH60Mkd2ukd3u68vsArbq97eKWltbtW/fPhUVFTnWFxUVae/evSH3qa6uDtr+3nvv1ccff6wLFy702lz7SyTHqF1eXp7S09NVWFionTt39uY0rRKNDJHdrpHd6LvWMgR01O/FpampSRcvXgx60F1aWlrQA+7aNTY2hty+ra1NTU1NvTbX/hLJMUpPT9eGDRvk9Xq1ZcsW5ebmqrCwULt37+6LKce8aGSI7HaN7EbftZYhoKPB/T2Bdi6XyzE2xgSt62r7UOsHknCOUW5urnJzcwPj/Px81dfXa/Xq1Zo6dWqvztMW0coQ2e0a2Y2uazFDQLt+P+OSmpqquLi4oP99nTx5Muh/Fe1GjBgRcvvBgwdr+PDhvTbX/hLJMQpl8uTJOnz4cLSnZ6VoZIjsdo3sRt+1liGgo34vLm63Wx6PR5WVlY71lZWVmjJlSsh98vPzg7bfsWOHJk6cqPj4+F6ba3+J5BiF4vP5lJ6eHu3pWSkaGSK7XSO70XetZQgI0n/XBV/WfrtkRUWFqa2tNQsXLjRJSUnm2LFjxhhjysvLzdy5cwPbt98OuGjRIlNbW2sqKioG/O2A4R6jl156yWzdutV8/vnnZv/+/aa8vNxIMl6vt79+hV519uxZ4/P5jM/nM5LMiy++aHw+X+CW297KENntGtntXH9lF7BVTBQXY4xZs2aNycrKMm6320yYMMHs2rUr8L3i4mIzbdo0x/ZVVVUmLy/PuN1uk52dbdatW9fHM+574Ryj559/3tx6660mMTHRXH/99ebHP/6x2bZtWz/Mum+030LbcSkuLjbG9G6GyG7XyO7V9Wd2ARu5jPm/q7oAAABiXL9f4wIAANBdFBcAAGANigsAALAGxQUAAFiD4gIAAKxBcQEAANaguAAAAGtQXAAAgDUoLgAAwBoUFwAAYA2KCwAAsMb/B5OZr5OOamUqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "predictions = model.predict(x_test[:9])\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "plt.imshow(x_test[i].reshape(28,28),cmap='gray')\n",
    "plt.title(f\"pred:{np.argmax(predictions[i])}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
