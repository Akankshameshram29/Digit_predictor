{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5d2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078162c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4375e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "def pad_to_square(img, pad_value=0):\n",
    "    \"\"\"Pad the image to make it square (for uniform 28x28 resizing).\"\"\"\n",
    "    h, w = img.shape\n",
    "    diff = abs(h - w)\n",
    "    if h > w:\n",
    "        pad_left = diff // 2\n",
    "        pad_right = diff - pad_left\n",
    "        padded = cv2.copyMakeBorder(img, 0, 0, pad_left, pad_right, cv2.BORDER_CONSTANT, value=pad_value)\n",
    "    else:\n",
    "        pad_top = diff // 2\n",
    "        pad_bottom = diff - pad_top\n",
    "        padded = cv2.copyMakeBorder(img, pad_top, pad_bottom, 0, 0, cv2.BORDER_CONSTANT, value=pad_value)\n",
    "    return padded\n",
    "def extract_digits_from_page(image_path, save_dir, label, min_width=10, min_height=10, preview=False):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(f\"\\nğŸ“„ Processing: {image_path} | Detected: {len(contours)} blobs\")\n",
    "    bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    bounding_boxes.sort(key=lambda b: (b[1], b[0]))  # sort top-to-bottom, then left-to-right\n",
    "    save_path = os.path.join(save_dir, str(label))\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    count = 0\n",
    "    for i, (x, y, w, h) in enumerate(bounding_boxes):\n",
    "        if w >= min_width and h >= min_height:\n",
    "            roi = thresh[y:y+h, x:x+w]\n",
    "            roi_padded = pad_to_square(roi)\n",
    "            digit_resized = cv2.resize(roi_padded, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "            file_path = os.path.join(save_path, f\"{label}_{count}.png\")\n",
    "            cv2.imwrite(file_path, digit_resized)\n",
    "            count += 1\n",
    "            if preview:\n",
    "                cv2.imshow(\"Digit\", digit_resized)\n",
    "                key = cv2.waitKey(150)\n",
    "                if key == 27:  # Esc key to stop preview\n",
    "                    break\n",
    "    if preview:\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    print(f\"âœ… Saved {count} digits to {save_path}\")\n",
    "def process_folder(folder_path, save_dir):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Example file naming: digit_4_page1.jpg â†’ label = 4\n",
    "            try:\n",
    "                label = int(file_name.split('_')[1])  # assumes format: digit_4_page1.jpg\n",
    "            except:\n",
    "                print(f\"âš ï¸ Skipping {file_name} (could not determine label)\")\n",
    "                continue\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            extract_digits_from_page(image_path, save_dir, label, preview=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17abda60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_0_page1.jpg | Detected: 55 blobs\n",
      "âœ… Saved 26 digits to custom_digit\\0\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_0_page11.jpg | Detected: 314 blobs\n",
      "âœ… Saved 60 digits to custom_digit\\0\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_1_page13.jpg | Detected: 136 blobs\n",
      "âœ… Saved 35 digits to custom_digit\\1\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_1_page2.jpg | Detected: 64 blobs\n",
      "âœ… Saved 23 digits to custom_digit\\1\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_2_page14.jpg | Detected: 198 blobs\n",
      "âœ… Saved 58 digits to custom_digit\\2\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_2_page3.jpg | Detected: 72 blobs\n",
      "âœ… Saved 33 digits to custom_digit\\2\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_3_page16.jpg | Detected: 125 blobs\n",
      "âœ… Saved 25 digits to custom_digit\\3\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_3_page4.jpg | Detected: 82 blobs\n",
      "âœ… Saved 29 digits to custom_digit\\3\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_4_page15.jpg | Detected: 118 blobs\n",
      "âœ… Saved 16 digits to custom_digit\\4\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_4_page5.jpg | Detected: 204 blobs\n",
      "âœ… Saved 29 digits to custom_digit\\4\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_5_pa.jpg | Detected: 113 blobs\n",
      "âœ… Saved 45 digits to custom_digit\\5\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_5_page17.jpg | Detected: 113 blobs\n",
      "âœ… Saved 45 digits to custom_digit\\5\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_5_page6.jpg | Detected: 38 blobs\n",
      "âœ… Saved 23 digits to custom_digit\\5\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_6_page18.jpg | Detected: 69 blobs\n",
      "âœ… Saved 22 digits to custom_digit\\6\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_6_page7.jpg | Detected: 118 blobs\n",
      "âœ… Saved 48 digits to custom_digit\\6\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_7_page20.jpg | Detected: 198 blobs\n",
      "âœ… Saved 32 digits to custom_digit\\7\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_7_page8.jpg | Detected: 48 blobs\n",
      "âœ… Saved 26 digits to custom_digit\\7\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_8_page19.jpg | Detected: 62 blobs\n",
      "âœ… Saved 18 digits to custom_digit\\8\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_8_page21.jpg | Detected: 381 blobs\n",
      "âœ… Saved 47 digits to custom_digit\\8\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_8_page9.jpg | Detected: 133 blobs\n",
      "âœ… Saved 39 digits to custom_digit\\8\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_9_page10.jpg | Detected: 77 blobs\n",
      "âœ… Saved 35 digits to custom_digit\\9\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_9_page12.jpg | Detected: 96 blobs\n",
      "âœ… Saved 15 digits to custom_digit\\9\n",
      "\n",
      "ğŸ“„ Processing: C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\\digit_9_page22.jpg | Detected: 58 blobs\n",
      "âœ… Saved 17 digits to custom_digit\\9\n",
      "âš ï¸ Skipping image1.jpg (could not determine label)\n",
      "âš ï¸ Skipping WhatsApp Image 2025-08-13 at 01.19.12_98757569.jpg (could not determine label)\n"
     ]
    }
   ],
   "source": [
    "process_folder(r\"C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\raw_digit_pages\",\"custom_digit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fdfa112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "def add_noise(img):\n",
    "    noise = np.random.randint(0, 50, img.shape, dtype='uint8')\n",
    "    return cv2.add(img, noise)\n",
    "def rotate_image(img, angle):\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
    "    return cv2.warpAffine(img, M, (w, h), borderValue=255)\n",
    "def shift_image(img, x_shift, y_shift):\n",
    "    M = np.float32([[1, 0, x_shift], [0, 1, y_shift]])\n",
    "    return cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), borderValue=255)\n",
    "def scale_image(img, fx, fy):\n",
    "    return cv2.resize(img, None, fx=fx, fy=fy, interpolation=cv2.INTER_LINEAR)\n",
    "def invert_image(img):\n",
    "    return 255 - img\n",
    "# Augment images in-place inside 'custom_digits' folder\n",
    "base_dir = r\"C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\custom_digit\"\n",
    "for digit in os.listdir(base_dir):\n",
    "    digit_path = os.path.join(base_dir, digit)\n",
    "    if not os.path.isdir(digit_path):\n",
    "        continue\n",
    "    image_files = [f for f in os.listdir(digit_path) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(digit_path, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # Generate 3 augmentations per image\n",
    "        for i in range(3):\n",
    "            rotated = rotate_image(img, angle=random.choice([-15, -10, 10, 15]))\n",
    "            shifted = shift_image(rotated, random.randint(-3, 3), random.randint(-3, 3))\n",
    "            noisy = add_noise(shifted)\n",
    "            final = invert_image(noisy) if random.random() < 0.5 else noisy\n",
    "            new_filename = f\"{os.path.splitext(img_name)[0]}_aug{i}.png\"\n",
    "            new_path = os.path.join(digit_path, new_filename)\n",
    "            cv2.imwrite(new_path, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bf085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_custom_digits(base_dir):\n",
    "    images, labels = [], []\n",
    "    for label in range(10):  # Assuming folders '0' to '9'\n",
    "        folder = os.path.join(base_dir, str(label))\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "        for fname in os.listdir(folder):\n",
    "            if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                img_path = os.path.join(folder, fname)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                img = img.astype(\"float32\") / 255.0\n",
    "                images.append(np.expand_dims(img, -1))\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "custom_data_dir = r\"C:\\Users\\akanksha meshram\\OneDrive\\Documents\\Desktop\\Digit_Prediction\\custom_digit\"\n",
    "x_custom, y_custom = load_custom_digits(custom_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01185971",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Expand dims to add channel for grayscale\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a75fe3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10), (10905, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "y_custom = to_categorical(y_custom, 10)\n",
    "y_train.shape, y_test.shape, y_custom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76efb7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined training data shape: (70905, 28, 28, 1)\n",
      "Combined training labels shape: (70905, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train_combined = np.concatenate((x_train, x_custom), axis=0)\n",
    "y_train_combined = np.concatenate((y_train, y_custom), axis=0)\n",
    "\n",
    "print(f\"Combined training data shape: {x_train_combined.shape}\")\n",
    "print(f\"Combined training labels shape: {y_train_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b738624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akanksha meshram\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82fb4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define ImageDataGenerator with augmentations similar to your OpenCV ones\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,        # rotate images randomly up to Â±15 degrees\n",
    "    width_shift_range=0.1,    # horizontal shift up to 10%\n",
    "    height_shift_range=0.1,   # vertical shift up to 10%\n",
    "    shear_range=0.1,          # shear angle in counter-clockwise direction in degrees\n",
    "    zoom_range=0.1,           # zoom in/out\n",
    "    fill_mode='nearest'       # fill missing pixels with nearest values\n",
    ")\n",
    "\n",
    "# Fit generator to your combined training data (optional for some augmentations)\n",
    "datagen.fit(x_train_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34813275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akanksha meshram\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 93ms/step - accuracy: 0.5945 - loss: 1.1942 - val_accuracy: 0.8938 - val_loss: 0.3275\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/498\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8438 - loss: 0.4610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akanksha meshram\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4610 - val_accuracy: 0.8940 - val_loss: 0.3274\n",
      "Epoch 3/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 93ms/step - accuracy: 0.8350 - loss: 0.5052 - val_accuracy: 0.9172 - val_loss: 0.2648\n",
      "Epoch 4/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.3605 - val_accuracy: 0.9167 - val_loss: 0.2660\n",
      "Epoch 5/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 95ms/step - accuracy: 0.8620 - loss: 0.4258 - val_accuracy: 0.9193 - val_loss: 0.2396\n",
      "Epoch 6/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.3311 - val_accuracy: 0.9185 - val_loss: 0.2421\n",
      "Epoch 7/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 87ms/step - accuracy: 0.8771 - loss: 0.3752 - val_accuracy: 0.9251 - val_loss: 0.2240\n",
      "Epoch 8/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.3080 - val_accuracy: 0.9237 - val_loss: 0.2264\n",
      "Epoch 9/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 95ms/step - accuracy: 0.8825 - loss: 0.3536 - val_accuracy: 0.9248 - val_loss: 0.2203\n",
      "Epoch 10/10\n",
      "\u001b[1m498/498\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.3588 - val_accuracy: 0.9236 - val_loss: 0.2285\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "# Fit the datagen on the combined training data (optional for some augmentations)\n",
    "datagen.fit(x_train_combined)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split combined data into train and validation sets\n",
    "x_train_final, x_val, y_train_final, y_val = train_test_split(\n",
    "    x_train_combined, y_train_combined, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Use the generator only on the training data\n",
    "train_generator = datagen.flow(x_train_final, y_train_final, batch_size=batch_size)\n",
    "\n",
    "# Train with validation data separately (pass x_val, y_val as validation_data)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    steps_per_epoch=len(x_train_final) // batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1545a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to my_digit_model.h5\n"
     ]
    }
   ],
   "source": [
    "# After model.fit(...)\n",
    "model.save('my_digit_model.h5')\n",
    "print(\"Model saved to my_digit_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac2029cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m204,928\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m1,290\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,036</span> (879.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225,036\u001b[0m (879.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,034</span> (879.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,034\u001b[0m (879.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('my_digit_model.h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d3bd259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST test accuracy: 0.9878\n",
      "Custom dataset accuracy: 0.5908\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"MNIST test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# 10. Evaluate on custom dataset\n",
    "custom_loss, custom_accuracy = model.evaluate(x_custom, y_custom, verbose=0)\n",
    "print(f\"Custom dataset accuracy: {custom_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "021eb799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "predictions = model.predict(x_test[:9])\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "plt.imshow(x_test[i].reshape(28,28),cmap='gray')\n",
    "plt.title(f\"pred:{np.argmax(predictions[i])}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
